{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv('GROQ_API_KEY')\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_ENVIRONMENT = os.getenv(\"PINECONE_ENVIRONMENT\")\n",
    "PINECONE_INDEX_NAME = os.getenv(\"PINECONE_INDEX_NAME\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import PyPDF2\n",
    "from pptx import Presentation\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from pinecone import Pinecone\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --- Configuration ---\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "pc = Pinecone(\n",
    "        api_key=os.getenv(\"PINECONE_API_KEY\")\n",
    "    )\n",
    "\n",
    "index_name = 'syllabus'\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "BASE_DIR = \"ctse_lecture_slides\"\n",
    "TEXT_DIR = \"ctse_extracted_txt_files\"\n",
    "MODULE_TEXT_DIR = \"ctse_merged_module_texts\"\n",
    "\n",
    "os.makedirs(TEXT_DIR, exist_ok=True)\n",
    "os.makedirs(MODULE_TEXT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# --- Extractor Class ---\n",
    "class SlideExtractor:\n",
    "    def __init__(self, base_dir: str, output_dir: str, merged_dir: str):\n",
    "        self.base_dir = base_dir\n",
    "        self.output_dir = output_dir\n",
    "        self.merged_dir = merged_dir\n",
    "\n",
    "    def extract_all(self):\n",
    "        for module_dir in sorted(os.listdir(self.base_dir)):\n",
    "            module_path = os.path.join(self.base_dir, module_dir)\n",
    "            if not os.path.isdir(module_path):\n",
    "                continue\n",
    "\n",
    "            module_texts = []\n",
    "\n",
    "            lecture_files = sorted(\n",
    "                glob.glob(os.path.join(module_path, \"*.pdf\")) + glob.glob(os.path.join(module_path, \"*.pptx\")),\n",
    "                key=lambda x: os.path.basename(x).lower()\n",
    "            )\n",
    "\n",
    "            for file_path in lecture_files:\n",
    "                if file_path.endswith(\".pdf\"):\n",
    "                    text = self._extract_pdf(file_path)\n",
    "                else:\n",
    "                    text = self._extract_pptx(file_path)\n",
    "\n",
    "                if text:\n",
    "                    self._save_individual_text(file_path, text)\n",
    "                    module_texts.append(f\"[{os.path.basename(file_path)}]\\n{text}\\n\")\n",
    "\n",
    "            # Save merged module-level file\n",
    "            if module_texts:\n",
    "                merged_path = os.path.join(self.merged_dir, f\"{module_dir}.txt\")\n",
    "                with open(merged_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(\"\\n\".join(module_texts))\n",
    "\n",
    "    def _extract_pdf(self, path: str) -> str:\n",
    "        try:\n",
    "            with open(path, \"rb\") as f:\n",
    "                reader = PyPDF2.PdfReader(f)\n",
    "                return \"\\n\".join(page.extract_text() or \"\" for page in reader.pages)\n",
    "        except Exception as e:\n",
    "            print(f\"[PDF ERROR] {path} - {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def _extract_pptx(self, path: str) -> str:\n",
    "        try:\n",
    "            prs = Presentation(path)\n",
    "            return \"\\n\".join(shape.text for slide in prs.slides for shape in slide.shapes if hasattr(shape, \"text\"))\n",
    "        except Exception as e:\n",
    "            print(f\"[PPTX ERROR] {path} - {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def _save_individual_text(self, original_path: str, content: str):\n",
    "        rel_path = os.path.relpath(original_path, self.base_dir)\n",
    "        txt_path = os.path.join(self.output_dir, rel_path.replace(\".pdf\", \".txt\").replace(\".pptx\", \".txt\"))\n",
    "        os.makedirs(os.path.dirname(txt_path), exist_ok=True)\n",
    "        with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(content)\n",
    "\n",
    "\n",
    "# --- Chunking & Embedding ---\n",
    "class Vectorizer:\n",
    "    def __init__(self, merged_dir: str, chunk_size: int = 1000, chunk_overlap: int = 100):\n",
    "        self.merged_dir = merged_dir\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "        self.embedder = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "    def process(self):\n",
    "        txt_files = sorted(glob.glob(os.path.join(self.merged_dir, \"*.txt\")))\n",
    "        for path in tqdm(txt_files, desc=\"Vectorizing merged module files\"):\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                content = f.read()\n",
    "\n",
    "            module_name = os.path.splitext(os.path.basename(path))[0]\n",
    "            chunks = self.text_splitter.split_text(content)\n",
    "\n",
    "            if chunks:\n",
    "                for i, text in enumerate(chunks):\n",
    "                    try:\n",
    "                        vector = self.embedder.embed_query(text)  # using embed_query for single text\n",
    "                        metadata = {\n",
    "                            \"module\": module_name,\n",
    "                            \"source\": f\"{module_name}.txt\",\n",
    "                            \"chunk_index\": i,\n",
    "                            \"text\": text,\n",
    "                        }\n",
    "                        index.upsert(\n",
    "                            vectors=[(f\"{module_name}-{i}\", vector, metadata)],\n",
    "                            namespace=module_name\n",
    "                        )\n",
    "                    except Exception as e:\n",
    "                        print(f\"[ERROR] Failed to process chunk {i} of {module_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Extracting text from slides...\n"
     ]
    }
   ],
   "source": [
    "print(\"üîç Extracting text from slides...\")\n",
    "extractor = SlideExtractor(BASE_DIR, TEXT_DIR, MODULE_TEXT_DIR)\n",
    "extractor.extract_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize the the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Vectorizing and storing into Pinecone...\n",
      "‚úÖ All done!\n"
     ]
    }
   ],
   "source": [
    "print(\"üß† Vectorizing and storing into Pinecone...\")\n",
    "vectorizer = Vectorizer(MODULE_TEXT_DIR)\n",
    "vectorizer.process()\n",
    "\n",
    "print(\"‚úÖ All done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SE4010 | Current Trends in SE| Introduction to Artificial Neural Networks| Jeewaka PereraBuilding Complete Neural Networks\\n‚Ä¢Stacking multiple Nerons to for a layer\\n‚Ä¢Organizing multiple Layers to form the network\\nSE4010 | Current Trends in SE| Introduction to Artificial Neural Networks| Jeewaka PereraTraining a neural net\\n1.Randomly initialize weights\\n2.Implement forward propagation to get the output at each \\nneuron \\n3.Compute the error at the output layer Etotal\\n4.Implement backpropagation to compute partial \\nderivatives   ùúïùê∏ùë°ùëúùë°ùëéùëô\\nùúïùë§ùëô\\nùëóùëò\\n5.Use Gradient descent or any other optimization technique \\nto update the weights to minimize Etotal\\n6.    Repeat this process over multiple iterations (epochs)  \\nuntil the error converges \\nSE4010 | Current Trends in SE| Introduction to Artificial Neural Networks| Jeewaka Perera', 'SE4010 | Current Trends in SE| Introduction to Artificial Neural Networks| Jeewaka PereraWhat is a Neural Network\\n‚Ä¢A Collection of Perceptron\\n‚Ä¢A Layer can be made by stacking a set of Perceptron \\nto get the outputs from the previous layer or Inputs\\n‚Ä¢A network is a set of layers that are arranged in a\\norganized manner (Sequential)\\n\\nSE4010 | Current Trends in SE| Introduction to Artificial Neural Networks| Jeewaka PereraStructure of an ANN', 'SE4010 | Current Trends in SE| Introduction to Artificial Neural Networks| Jeewaka Perera']\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone\n",
    "from langchain.vectorstores import Pinecone as Pcone\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Connect to index\n",
    "index = pc.Index(PINECONE_INDEX_NAME)\n",
    "\n",
    "embedder = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "def retrieve_similar_questions(query, top_k=3):\n",
    "    vector = embedder.embed_query(query)\n",
    "    namespace = 'ctse'\n",
    "    results = index.query(\n",
    "        vector=vector,\n",
    "        top_k=top_k,\n",
    "        namespace=namespace,\n",
    "        include_metadata=True,\n",
    "    )\n",
    "\n",
    "    texts = [match[\"metadata\"][\"text\"] for match in results[\"matches\"]]\n",
    "\n",
    "    return texts[:top_k]\n",
    "\n",
    "print(retrieve_similar_questions(\"how to train a neural net\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the LLM and prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"mistral-saba-24b\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "system = f\"\"\"\n",
    "    You are an expert in answering user question with provide context.\n",
    "\"\"\"\n",
    "\n",
    "human = r\"\"\"\n",
    "    Answer the question according to context.\n",
    "    Context: {context}\n",
    "    Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])\n",
    "parser = StrOutputParser()\n",
    "\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: Transformers are a type of neural network architecture introduced in 2017, primarily for natural language processing (NLP) tasks. They are based on a self-attention mechanism, which allows the model to focus on different parts of the input sequence when processing each token. This mechanism enables the model to capture long-range dependencies and relationships within the data more effectively than traditional recurrent neural networks (RNNs).\n",
      "\n",
      "Key features of Transformers include:\n",
      "\n",
      "1. **Self-Attention Mechanism**: This allows the model to weigh the importance of different parts of the input sequence when making predictions, enabling it to handle long-range dependencies.\n",
      "2. **Parallel Processing**: Unlike RNNs, which process sequences step-by-step, Transformers can process the entire input sequence in parallel. This makes them much faster and more efficient, especially for long sequences.\n",
      "3. **Versatility**: Transformers have been successfully applied to a variety of tasks, including language translation, question answering, text summarization, and even non-language tasks like image processing and music generation.\n",
      "\n",
      "Transformers have become a cornerstone in modern NLP due to their ability to handle variable-length sequences and capture complex dependencies within the data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "question = \"explain transformers?\"\n",
    "\n",
    "context = retrieve_similar_questions(question)\n",
    "\n",
    "answer = chain.invoke({\"context\": context, \"question\": question})\n",
    "print(f\"\\nAnswer: {answer}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
